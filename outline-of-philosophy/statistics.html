<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
      "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Ryan Reece" />
  <meta name="date" content="Sun Jan 19, 2020" />
  <title>Philosophy of statistics - Ryan&#8217;s Outline of Philosophy</title>
  <meta name="description" content="Ryan Reece&#8217;s outline of philosophy" />
  <link rel="stylesheet" type="text/css" href="templates/markdown-memo-alt-blue.css"/>
  <link rel="icon" type="image/png" href="img/markdown-favicon-196x196.png" />

<!--- Google Analytics Tracking stuff  -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-55199032-1', 'auto');
  ga('send', 'pageview');
</script>

<!--- MathJax stuff -->
<script type="text/javascript" src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });
</script>

<!--- toggle_more function  -->
<script type="text/javascript">
    //<![CDATA[
    function toggle_more(objID) {
        if (!document.getElementById) return;
        var ob = document.getElementById(objID).style;
        ob.display = (ob.display == 'block')?'none':'block';
        var ob2 = document.getElementById('link:'+objID);
        ob2.className = (ob2.className == 'open') ? 'closed' : 'open';
    }
    //]]>
</script>

</head>

<body>

<div id="site_header">
    <a href="./">Ryan&#8217;s Outline of Philosophy</a>
</div>

<!--
<div id="beforebody">
</div>
-->

<div class="nav">
<ul>
    <li> <a href="./">&#8634;&nbsp;Contents</a> </li>
    <li> <a href="#site_footer">&#8615;&nbsp;Bottom</a> </li>
    <li> <a href="./scientific-method.html">&#8612;&nbsp;Previous</a> </li>
    <li> <a href="./scientific-realism.html">&#8614;&nbsp;Next</a> </li>
</ul>
</div>

<div id="mainbody">
<div id="pagecontainer">

<h1 id="philosophy-of-statistics">Philosophy of statistics</h1>
<p>Statistics are <em>way</em> important in addressing the problem of induction.</p>
<h3 id="contents" class="unnumbered">Contents</h3>
<ol style="list-style-type: decimal">
<li><a href="statistics.html#issues-and-positions">Issues and positions</a>
<ol style="list-style-type: decimal">
<li><a href="statistics.html#problem-of-induction">Problem of induction</a></li>
<li><a href="statistics.html#probability-and-uncertainty">Probability and uncertainty</a></li>
<li><a href="statistics.html#early-investigators">Early investigators</a></li>
<li><a href="statistics.html#foundations-of-statistics">Foundations of statistics</a></li>
<li><a href="statistics.html#point-estimation-and-confidence-intervals">Point estimation and confidence intervals</a></li>
<li><a href="statistics.html#statistical-hypothesis-testing">Statistical hypothesis testing</a></li>
<li><a href="statistics.html#systematic-uncertainties">Systematic uncertainties</a></li>
<li><a href="statistics.html#p-value-controversy">P-value controversy</a></li>
<li><a href="statistics.html#machine-learning">Machine learning</a></li>
<li><a href="statistics.html#auto-science">Auto-science</a></li>
<li><a href="statistics.html#implications-for-the-realism-debate">Implications for the realism debate</a></li>
</ol></li>
<li><a href="statistics.html#my-thoughts">My thoughts</a></li>
<li><a href="statistics.html#annotated-bibliography">Annotated bibliography</a>
<ol style="list-style-type: decimal">
<li><a href="statistics.html#mayo-d.g.-1996.-error-and-the-growth-of-experimental-knowledge.">Mayo, D.G. (1996). <em>Error and the Growth of Experimental Knowledge</em>.</a></li>
<li><a href="statistics.html#cowan-g.-1998.-statistical-data-analysis.">Cowan, G. (1998). <em>Statistical Data Analysis</em>.</a></li>
<li><a href="statistics.html#james-f.-2006.-statistical-methods-in-experimental-physics-2nd-ed.">James, F. (2006). <em>Statistical Methods in Experimental Physics, 2nd Ed.</em></a></li>
<li><a href="statistics.html#cowan-g.-et-al.-2011.-asymptotic-formulae-for-likelihood-based-tests-of-new-physics.">Cowan, G. <em>et al.</em> (2011). Asymptotic formulae for likelihood-based tests of new physics.</a></li>
<li><a href="statistics.html#atlas-collaboration.-2012.-combined-search-for-the-standard-model-higgs-boson-in-pp-collisions-at-sqrts-7-tev-with-the-atlas-detector.">ATLAS Collaboration. (2012). Combined search for the Standard Model Higgs boson in <span class="math inline">(pp)</span> collisions at <span class="math inline">()</span> = 7 TeV with the ATLAS detector.</a></li>
<li><a href="statistics.html#cranmer-k-2015.-practical-statistics-for-the-lhc.">Cranmer, K (2015). Practical statistics for the LHC.</a></li>
<li><a href="statistics.html#more-articles-to-do">More articles to do</a></li>
</ol></li>
<li><a href="statistics.html#links-and-encyclopedia-articles">Links and encyclopedia articles</a>
<ol style="list-style-type: decimal">
<li><a href="statistics.html#sep">SEP</a></li>
<li><a href="statistics.html#iep">IEP</a></li>
<li><a href="statistics.html#scholarpedia">Scholarpedia</a></li>
<li><a href="statistics.html#wikipedia">Wikipedia</a></li>
<li><a href="statistics.html#others">Others</a></li>
</ol></li>
<li><a href="statistics.html#references">References</a></li>
</ol>
<h2 id="issues-and-positions">Issues and positions</h2>
<h3 id="problem-of-induction">Problem of induction</h3>
<ul>
<li>How do we infer universals from particulars?</li>
<li>Hume<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>
<ul>
<li>Weintraub<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></li>
</ul></li>
<li>Mill</li>
<li>Peirce</li>
<li>Reichenbach<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></li>
<li>Carnap<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></li>
<li>Salmon<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></li>
<li>Good<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></li>
<li>Hacking<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></li>
<li>Huber<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></li>
</ul>
<blockquote>
<p>[I]n Peirce&#8217;s phrase, inductions are ampliative. Induction can amplify and generalize our experience, broaden and deepen our empirical knowledge. Deduction on the other hand is explicative. Deduction orders and rearranges our knowledge without adding to its content.<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a></p>
</blockquote>
<h3 id="probability-and-uncertainty">Probability and uncertainty</h3>
<ul>
<li>Kolmogorov</li>
<li>Frequentist vs Bayesian probability
<ul>
<li><a href="https://en.wikipedia.org/wiki/Thomas_Bayes">Bayes, Thomas (1701-1761)</a></li>
</ul></li>
<li>Accuracy vs precision<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a></li>
</ul>
<h3 id="early-investigators">Early investigators</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/John_Graunt">Graunt, John (1620-1674)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Jacob_Bernoulli">Bernoulli, Jacob (1655-1705)</a>
<ul>
<li><em>Ars Conjectandi</em> (1713, posthumous)</li>
<li>First modern phrasing of the problem of parameter estimation<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a></li>
<li><p>Early vision of decision theory:</p>
<blockquote>
<p>The art of measuring, as precisely as possible, probabilities of things, with the goal that we would be able always to choose or follow in our judgments and actions that course, which will have been determined to be better, more satisfactory, safer or more advantageous.</p>
</blockquote>
&#8211; <em>Ars Conjectandi</em> (1713) Chapter II, Part IV, defining the art of conjecture [<a href="https://en.wikiquote.org/wiki/Jacob_Bernoulli">wikiquote</a>].</li>
<li>See Hacking<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a></li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Thomas_Bayes">Bayes, Thomas (1701-1761)</a></li>
<li><a href="http://en.wikipedia.org/wiki/Gauss">Gauss, Carl Friedrich (1777-1855)</a></li>
<li><a href="https://en.wikipedia.org/wiki/John_Stuart_Mill">Mill, John Stuart (1806-1873)</a></li>
<li><a href="https://en.wikipedia.org/wiki/John_Venn">Venn, John (1834-1923)</a>
<ul>
<li><em>The Logic of Chance</em> (1866)<a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a></li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Charles_Sanders_Peirce">Peirce, Charles Sanders (1839-1914)</a>
<ul>
<li>Formulated modern statistics in &#8220;Illustrations of the Logic of Science&#8221; (1877-1878) and &#8220;A Theory of Probable Inference&#8221; in <em>Studies in Logic</em> (1883).<a href="#fn14" class="footnoteRef" id="fnref14"><sup>14</sup></a></li>
<li>With a repeated measures design, introduced blinded, controlled randomized experiments (before Fisher).</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/John_Tukey">Turkey, John (1915-2000)</a></li>
</ul>
<h3 id="foundations-of-statistics">Foundations of statistics</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Karl_Pearson">Pearson, Karl (1857-1936)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ronald_Fisher">Fisher, Ronald (1890-1972)</a>
<ul>
<li>Fisher significance of the null hypothesis (<span class="math inline">\(p\)</span>-values)
<ul>
<li>On an absolute criterion for fitting frequency curves.<a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a></li>
<li>Frequency distribution of the values of the correlation coefficient in samples of indefinitely large population.<a href="#fn16" class="footnoteRef" id="fnref16"><sup>16</sup></a></li>
<li>On the &#8220;probable error&#8221; of a coefficient of correlation deduced from a small sample<a href="#fn17" class="footnoteRef" id="fnref17"><sup>17</sup></a> - definition of <em>likelihood</em></li>
</ul></li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Jerzy_Neyman">Neyman, Jerzy (1894-1981)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Egon_Pearson">Pearson, Egon (1895-1980)</a>
<ul>
<li>Neyman-Pearson confidence intervals with fixed error probabilities (also <span class="math inline">\(p\)</span>-values but considering two hypotheses involves two types of errors)</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Harold_Jeffreys">Jeffreys, Harold (1891-1989)</a>
<ul>
<li>objective (non-informative) Jeffreys priors</li>
</ul></li>
<li><a href="http://en.wikipedia.org/wiki/Likelihood_principle">Likelihood principle</a>
<ul>
<li>The likelihood principle is the proposition that, given a statistical model and a data sample, all the evidence relevant to model parameters is contained in the likelihood function.</li>
<li>The history of likelihood<a href="#fn18" class="footnoteRef" id="fnref18"><sup>18</sup></a>
<ul>
<li>Allan Birnbaum proved that the likelihood principle follows from two more primitive and seemingly reasonable principles, the <a href="https://en.wikipedia.org/wiki/Conditionality_principle">conditionality principle</a> and the <a href="https://en.wikipedia.org/wiki/Sufficient_statistic">sufficiency principle</a>.<a href="#fn19" class="footnoteRef" id="fnref19"><sup>19</sup></a></li>
<li>Hacking identified the &#8220;law of likelihood&#8221;.<a href="#fn20" class="footnoteRef" id="fnref20"><sup>20</sup></a></li>
</ul></li>
<li><em>The Likelihood Principle</em><a href="#fn21" class="footnoteRef" id="fnref21"><sup>21</sup></a></li>
<li>Criticisms:
<ul>
<li>Evans<a href="#fn22" class="footnoteRef" id="fnref22"><sup>22</sup></a></li>
<li>Mayo<a href="#fn23" class="footnoteRef" id="fnref23"><sup>23</sup></a></li>
</ul></li>
<li>Gandenberger&#8217;s proof<a href="#fn24" class="footnoteRef" id="fnref24"><sup>24</sup></a></li>
<li>Violated by both Frequentists and Bayesians</li>
<li><a href="https://en.wikipedia.org/wiki/Likelihoodist_statistics">Likelihoodist statistics</a></li>
</ul></li>
<li>&#8220;Statistics Wars&#8221;</li>
<li>Responses
<ul>
<li>Cox</li>
<li>Carnap</li>
<li>Hacking
<ul>
<li><em>Logic of Statistical Inference</em><a href="#fn25" class="footnoteRef" id="fnref25"><sup>25</sup></a></li>
</ul></li>
<li>Berger<a href="#fn26" class="footnoteRef" id="fnref26"><sup>26</sup></a></li>
<li>Mayo
<ul>
<li>Learning from Error<a href="#fn27" class="footnoteRef" id="fnref27"><sup>27</sup></a></li>
<li>Error statistics<a href="#fn28" class="footnoteRef" id="fnref28"><sup>28</sup></a></li>
<li><em>Statistical Inference as Severe Testing</em><a href="#fn29" class="footnoteRef" id="fnref29"><sup>29</sup></a></li>
</ul></li>
</ul></li>
<li>Pedagogy
<ul>
<li>Kendall<a href="#fn30" class="footnoteRef" id="fnref30"><sup>30</sup></a></li>
<li>James<a href="#fn31" class="footnoteRef" id="fnref31"><sup>31</sup></a></li>
<li>Cowan<a href="#fn32" class="footnoteRef" id="fnref32"><sup>32</sup></a></li>
<li>Cranmer<a href="#fn33" class="footnoteRef" id="fnref33"><sup>33</sup></a></li>
<li>Weisberg<a href="#fn34" class="footnoteRef" id="fnref34"><sup>34</sup></a></li>
</ul></li>
</ul>
<h3 id="point-estimation-and-confidence-intervals">Point estimation and confidence intervals</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Inverse_problem">Inverse problem</a></li>
<li>regression</li>
<li>MLE: Maximum likelihood estimators, Fisher<a href="#fn35" class="footnoteRef" id="fnref35"><sup>35</sup></a></li>
<li>Cram&#233;r-Rao bound<a href="#fn36" class="footnoteRef" id="fnref36"><sup>36</sup></a></li>
<li><span class="math inline">\(\chi^2\)</span></li>
</ul>
<h3 id="statistical-hypothesis-testing">Statistical hypothesis testing</h3>
<ul>
<li>classification</li>
<li>Type-1 and type-2 errors in Neyman-Pearson theory</li>
<li>Power and confidence</li>
<li>Neyman-Pearson lemma<a href="#fn37" class="footnoteRef" id="fnref37"><sup>37</sup></a></li>
<li>Wilks<a href="#fn38" class="footnoteRef" id="fnref38"><sup>38</sup></a> and Wald<a href="#fn39" class="footnoteRef" id="fnref39"><sup>39</sup></a></li>
<li><span class="math inline">\(p\)</span>-values and significance<a href="#fn40" class="footnoteRef" id="fnref40"><sup>40</sup></a></li>
<li>Flip-flopping and Feldman-Cousins confidence intervals<a href="#fn41" class="footnoteRef" id="fnref41"><sup>41</sup></a></li>
<li>Asymptotics<a href="#fn42" class="footnoteRef" id="fnref42"><sup>42</sup></a></li>
</ul>
<h3 id="systematic-uncertainties">Systematic uncertainties</h3>
<ul>
<li>Class-1, class-2, and class-3 systematic uncertanties (good, bad, ugly), Classification by Pekka Sinervo (PhyStat2003)<a href="#fn43" class="footnoteRef" id="fnref43"><sup>43</sup></a></li>
<li>Not to be confused with type-1 and type-2 errors in Neyman-Pearson theory</li>
</ul>
<div class="figure">
<img src="img/systematic-uncertainties-sinervo.png" alt="Figure 1: Classification of measurement uncertainties (philosophy-in-figures.tumblr.com)." id="fig:systematic-uncertainties-sinervo" />
<p class="caption">Figure 1: Classification of measurement uncertainties (<a href="http://philosophy-in-figures.tumblr.com/post/150371555016/classification-of-measurement-uncertainties">philosophy-in-figures.tumblr.com</a>).</p>
</div>
<h3 id="p-value-controversy">P-value controversy</h3>
<blockquote>
<p>[N]o isolated experiment, however significant in itself, can suffice for the experimental demonstration of any natural phenomenon; for the &#8220;one chance in a million&#8221; will undoubtedly occur, with no less and no more than its appropriate frequency, however surprised we may be that it should occur to us. In order to assert that a natural phenomenon is experimentally demonstrable we need, not an isolated record, but a reliable method of procedure. In relation to the test of significance, we may say that a phenomenon is experimentally demonstrable when we know how to conduct an experiment which will rarely fail to give us a statistically significant result.<a href="#fn44" class="footnoteRef" id="fnref44"><sup>44</sup></a></p>
</blockquote>
<ul>
<li>file-drawer effect = look-elsewhere effect</li>
<li><a href="https://hiphination.org/episodes/episode-7-hackademics-ii-the-hackers/">Hi-Phi Nation, episode 7</a></li>
<li>ASA statement on <span class="math inline">\(p\)</span>-values<a href="#fn45" class="footnoteRef" id="fnref45"><sup>45</sup></a></li>
<li><a href="http://www.nature.com/news/big-names-in-statistics-want-to-shake-up-much-maligned-p-value-1.22375">Big names in statistics want to shake up much-maligned P value</a><a href="#fn46" class="footnoteRef" id="fnref46"><sup>46</sup></a></li>
</ul>
<h3 id="machine-learning">Machine learning</h3>
<ul>
<li>classification and regression</li>
<li>supervised and unsupervised learning</li>
<li>Hastie, Tibshirani, &amp; Friedman<a href="#fn47" class="footnoteRef" id="fnref47"><sup>47</sup></a></li>
</ul>
<h3 id="auto-science">Auto-science</h3>
<div class="figure">
<img src="img/BDEC-scientific-method.png" alt="Figure 2: The inference cycle for the process of scientific inquiry. The three distinct forms of inference (abduction, deduction, and induction) facilitate an all-encompassing vision, enabling HPC and HDA to converge in a rational and structured manner. HPC: high- performance computing; HDA: high-end data analysis (Asch, M. et al., 2018)." id="fig:BDEC-scientific-method" />
<p class="caption">Figure 2: The inference cycle for the process of scientific inquiry. The three distinct forms of inference (abduction, deduction, and induction) facilitate an all-encompassing vision, enabling HPC and HDA to converge in a rational and structured manner. HPC: high- performance computing; HDA: high-end data analysis <span class="citation">(Asch, M. et al., 2018)</span>.</p>
</div>
<ul>
<li>Big data and extreme-scale computing: Pathways to Convergence-Toward a shaping strategy for a future software and data ecosystem for scientific inquiry.<a href="#fn48" class="footnoteRef" id="fnref48"><sup>48</sup></a>
<ul>
<li>Note that this description of abduction is missing that it is normative (i.e. &#8220;best-fit&#8221;).</li>
</ul></li>
<li>Learning New Physics from a Machine<a href="#fn49" class="footnoteRef" id="fnref49"><sup>49</sup></a></li>
<li>The End of Theory: The data deluge makes the scientific method obsolete.<a href="#fn50" class="footnoteRef" id="fnref50"><sup>50</sup></a></li>
</ul>
<h3 id="implications-for-the-realism-debate">Implications for the realism debate</h3>
<ul>
<li>See the outline on <a href="scientific-realism.html">Scientific realism</a></li>
<li>Perone, C.S. (2018). <a href="http://blog.christianperone.com/2018/05/nlp-word-representations-and-the-wittgenstein-philosophy-of-language/">NLP word representations and the Wittgenstein philosophy of language</a>.</li>
<li>Rationalism and empiricism in artificial intellegence: <a href="https://www.cambridge.org/core/journals/natural-language-engineering/article/survey-of-25-years-of-evaluation/E4330FAEB9202EC490218E3220DDA291">Church, K.W. &amp; Joel, H. (2019). A survey of 25 years of evaluation.</a></li>
</ul>
<h2 id="my-thoughts">My thoughts</h2>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<h2 id="annotated-bibliography">Annotated bibliography</h2>
<h3 id="mayo-d.g.-1996.-error-and-the-growth-of-experimental-knowledge.">Mayo, D.G. (1996). <em>Error and the Growth of Experimental Knowledge</em>.</h3>
<ul>
<li><span class="citation">Mayo (1996)</span></li>
</ul>
<h4 id="my-thoughts-1">My thoughts</h4>
<ul>
<li>TODO</li>
</ul>
<hr />
<h3 id="cowan-g.-1998.-statistical-data-analysis.">Cowan, G. (1998). <em>Statistical Data Analysis</em>.</h3>
<ul>
<li><span class="citation">Cowan (1998)</span> and <span class="citation">Cowan (2016)</span></li>
</ul>
<h4 id="my-thoughts-2">My thoughts</h4>
<ul>
<li>TODO</li>
</ul>
<hr />
<h3 id="james-f.-2006.-statistical-methods-in-experimental-physics-2nd-ed.">James, F. (2006). <em>Statistical Methods in Experimental Physics, 2nd Ed.</em></h3>
<ul>
<li><span class="citation">James (2006)</span></li>
</ul>
<h4 id="my-thoughts-3">My thoughts</h4>
<ul>
<li>TODO</li>
</ul>
<hr />
<h3 id="cowan-g.-et-al.-2011.-asymptotic-formulae-for-likelihood-based-tests-of-new-physics.">Cowan, G. <em>et al.</em> (2011). Asymptotic formulae for likelihood-based tests of new physics.</h3>
<ul>
<li><span class="citation">Cowan et al. (2011)</span></li>
<li>Glen Cowan, Kyle Cranmer, Eilam Gross, Ofer Vitells</li>
</ul>
<h4 id="my-thoughts-4">My thoughts</h4>
<ul>
<li>TODO</li>
</ul>
<hr />
<h3 id="atlas-collaboration.-2012.-combined-search-for-the-standard-model-higgs-boson-in-pp-collisions-at-sqrts-7-tev-with-the-atlas-detector.">ATLAS Collaboration. (2012). Combined search for the Standard Model Higgs boson in <span class="math inline">\(pp\)</span> collisions at <span class="math inline">\(\sqrt{s}\)</span> = 7 TeV with the ATLAS detector.</h3>
<ul>
<li><span class="citation">ATLAS Collaboration (2012)</span></li>
<li><a href="http://arxiv.org/abs/1207.0319">arxiv:1207.0319</a></li>
</ul>
<h4 id="my-thoughts-5">My thoughts</h4>
<ul>
<li>TODO</li>
</ul>
<hr />
<h3 id="cranmer-k-2015.-practical-statistics-for-the-lhc.">Cranmer, K (2015). Practical statistics for the LHC.</h3>
<ul>
<li><span class="citation">Cranmer (2015)</span></li>
</ul>
<h4 id="my-thoughts-6">My thoughts</h4>
<ul>
<li>TODO</li>
</ul>
<hr />
<h3 id="more-articles-to-do">More articles to do</h3>
<ul>
<li>Univariate Distribution Relationships<a href="#fn51" class="footnoteRef" id="fnref51"><sup>51</sup></a></li>
<li><em>All of Statistics</em><a href="#fn52" class="footnoteRef" id="fnref52"><sup>52</sup></a></li>
<li><em>The Foundations of Statistics</em><a href="#fn53" class="footnoteRef" id="fnref53"><sup>53</sup></a></li>
</ul>
<h2 id="links-and-encyclopedia-articles">Links and encyclopedia articles</h2>
<h3 id="sep">SEP</h3>
<ul>
<li><a href="http://plato.stanford.edu/entries/abduction/">Abduction</a></li>
<li><a href="http://plato.stanford.edu/entries/knowledge-analysis/">Analysis of Knowledge</a></li>
<li><a href="https://plato.stanford.edu/entries/bayes-theorem/">Bayes&#8217; Theorem</a></li>
<li><a href="https://plato.stanford.edu/entries/epistemology-bayesian/">Bayesian Epistemology</a></li>
<li><a href="https://plato.stanford.edu/entries/causal-models/">Causal Models</a></li>
<li><a href="http://plato.stanford.edu/entries/causation-process/">Causal Processes</a></li>
<li><a href="https://plato.stanford.edu/entries/dutch-book/">Dutch Book Arguments</a></li>
<li><a href="http://plato.stanford.edu/entries/epistemology/">Epistemology</a></li>
<li><a href="http://plato.stanford.edu/entries/justep-foundational/">Foundationalist Theories of Epistemic Justification</a></li>
<li><a href="http://plato.stanford.edu/entries/hume/">Hume, David (1711-1776)</a></li>
<li><a href="http://plato.stanford.edu/entries/identity-indiscernible/">Identity of Indiscernibles</a></li>
<li><a href="http://plato.stanford.edu/entries/induction-problem/">Induction, The problem of</a></li>
<li><a href="https://plato.stanford.edu/entries/logic-probability/">Logic and Probability</a></li>
<li><a href="http://plato.stanford.edu/entries/epistemology-naturalized/">Naturalized epistemology</a></li>
<li><a href="https://plato.stanford.edu/entries/peirce/">Peirce, Charles Sanders (1839-1914)</a></li>
<li><a href="http://plato.stanford.edu/entries/popper/">Popper, Karl (1902-1994)</a></li>
<li><a href="http://plato.stanford.edu/entries/sufficient-reason/">Principle of Sufficient Reason</a></li>
<li><a href="https://plato.stanford.edu/entries/probability-interpret/">Probability, Interpretations of</a></li>
<li><a href="https://plato.stanford.edu/entries/causation-probabilistic/">Probabilistic Causation</a></li>
<li><a href="https://plato.stanford.edu/entries/reichenbach/">Reichenbach, Hans (1891-1953)</a></li>
<li><a href="http://plato.stanford.edu/entries/scientific-explanation/">Scientific Explanation</a></li>
<li><a href="http://plato.stanford.edu/entries/statistics/">Statistics, Philosophy of</a></li>
</ul>
<h3 id="iep">IEP</h3>
<ul>
<li><a href="http://www.iep.utm.edu/epistemo/">Epistemology</a></li>
<li><a href="http://www.iep.utm.edu/hempel/">Hempel, Carl Gustav (1905-1997)</a></li>
<li><a href="http://www.iep.utm.edu/hume-cau/">Hume, David (1711-1776)</a></li>
<li><a href="http://www.iep.utm.edu/naturali/">Naturalism</a></li>
<li><a href="http://www.iep.utm.edu/nat-epis/">Naturalistic Epistemology</a></li>
<li><a href="https://www.iep.utm.edu/peircebi/">Peirce, Charles Sanders (1839-1914)</a></li>
<li><a href="http://www.iep.utm.edu/red-ism/">Reductionism</a></li>
<li><a href="http://www.iep.utm.edu/safety-c/">Safety Condition for Knowledge, The</a></li>
<li><a href="http://www.iep.utm.edu/simplici/">Simplicity in the philosophy of science</a></li>
<li><a href="http://www.iep.utm.edu/ockham/">William of Ockham (1280-1349)</a></li>
</ul>
<h3 id="scholarpedia">Scholarpedia</h3>
<ul>
<li><a href="http://www.scholarpedia.org/article/Algorithmic_probability">Algorithmic probability</a></li>
</ul>
<h3 id="wikipedia">Wikipedia</h3>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Abductive_reasoning">Abductive reasoning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Algorithmic_information_theory">Algorithmic information theory</a></li>
<li><a href="https://en.wikipedia.org/wiki/Algorithmic_probability">Algorithmic probability</a></li>
<li><a href="https://en.wikipedia.org/wiki/Analysis_of_variance">Analysis of variance</a></li>
<li><a href="https://en.wikipedia.org/wiki/Aumann%27s_agreement_theorem">Aumann&#8217;s agreement theorem</a></li>
<li><a href="https://en.wikipedia.org/wiki/Thomas_Bayes">Bayes, Thomas (1701-1761)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bayesian_inference">Bayesian inference</a></li>
<li><a href="https://en.wikipedia.org/wiki/Allan_Birnbaum">Birnbaum, Allan (1923-1976)</a></li>
<li><a href="http://en.wikipedia.org/wiki/Bootstrapping_(statistics)">Bootstrapping</a></li>
<li><a href="https://en.wikipedia.org/wiki/Confidence_interval">Confidence interval</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cosmic_variance">Cosmic variance</a></li>
<li><a href="http://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound">Cram&#233;r-Rao bound</a></li>
<li><a href="https://en.wikipedia.org/wiki/Data_science">Data science</a></li>
<li><a href="https://en.wikipedia.org/wiki/Decision_theory">Decision theory</a></li>
<li><a href="https://en.wikipedia.org/wiki/Deductive-nomological_model">Deductive-nomological model</a></li>
<li><a href="http://en.wikipedia.org/wiki/Empiricism">Empircism</a></li>
<li><a href="http://en.wikipedia.org/wiki/Epistemology">Epistemology</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ronald_Fisher">Fisher, Ronald (1890-1962)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Frequentist_inference">Frequentist inference</a></li>
<li><a href="https://en.wikipedia.org/wiki/Foundations_of_statistics">Foundations of statistics</a></li>
<li><a href="http://en.wikipedia.org/wiki/Gauss">Gauss, Carl Friedrich (1777-1855)</a></li>
<li><a href="https://en.wikipedia.org/wiki/German_tank_problem">German tank problem</a></li>
<li><a href="https://en.wikipedia.org/wiki/William_Sealy_Gosset">Gosset, William Sealy (1876-1937)</a></li>
<li><a href="https://en.wikipedia.org/wiki/John_Graunt">Graunt, John (1620-1674)</a></li>
<li><a href="https://en.wikipedia.org/wiki/History_of_probability">History of probability</a></li>
<li><a href="https://en.wikipedia.org/wiki/History_of_statistics">History of statistics</a></li>
<li><a href="http://en.wikipedia.org/wiki/David_Hume">Hume, David (1711-1776)</a></li>
<li><a href="http://en.wikipedia.org/wiki/Problem_of_induction">Induction, The problem of</a></li>
<li><a href="https://en.wikipedia.org/wiki/Inductive_reasoning">Inductive reasoning</a></li>
<li><a href="http://en.wikipedia.org/wiki/Interval_estimation">Interval estimation</a></li>
<li><a href="https://en.wikipedia.org/wiki/Inverse_problem">Inverse problem</a></li>
<li><a href="https://en.wikipedia.org/wiki/Alexey_Ivakhnenko">Ivakhnenko, Alexey (1913-2007)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Richard_Jeffrey">Jeffrey, Richard (1926-2002)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Harold_Jeffreys">Jeffreys, Harold (1891-1989)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Jeffreys_prior">Jeffreys prior</a></li>
<li><a href="https://en.wikipedia.org/wiki/Andrey_Kolmogorov">Kolmogorov, Andrey (1903-1987)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Kolmogorov_complexity">Kolmogorov complexity</a></li>
<li><a href="https://en.wikipedia.org/wiki/Pierre-Simon_Laplace">Laplace, Pierre-Simon (1749-1827)</a></li>
<li><a href="http://en.wikipedia.org/wiki/Likelihood_principle">Likelihood principle</a></li>
<li><a href="https://en.wikipedia.org/wiki/Likelihoodist_statistics">Likelihoodist statistics</a></li>
<li><a href="https://en.wikipedia.org/wiki/Machine_learning">Machine learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">Maximum likelihood estimation</a></li>
<li><a href="https://en.wikipedia.org/wiki/John_Stuart_Mill">Mill, John Stuart (1806-1873)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Jerzy_Neyman">Neyman, Jerzy (1894-1981)</a></li>
<li><a href="http://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma">Neyman-Pearson lemma</a></li>
<li><a href="http://en.wikipedia.org/wiki/William_of_Ockham">Ockham, William of (1287-1347)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Egon_Pearson">Pearson, Egon (1895-1980)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Karl_Pearson">Pearson, Karl (1857-1936)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Charles_Sanders_Peirce">Peirce, Charles Sanders (1839-1914)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Sim%C3%A9on_Denis_Poisson">Poisson, Sim&#233;on Denis (1781-1840)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Karl_Popper">Popper, Karl (1902-1994)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Principle_of_sufficient_reason">Principle of sufficient reason</a></li>
<li><a href="https://en.wikipedia.org/wiki/Leonard_Jimmie_Savage">Savage, Leonard Jimmie (1917-1971)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ray_Solomonoff">Solomonoff, Ray (1926-2009)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference">Solomonoff&#8217;s theory of inductive inference</a></li>
<li><a href="http://en.wikipedia.org/wiki/Statistical_classification">Statistical classification</a></li>
<li><a href="http://en.wikipedia.org/wiki/Statistical_hypothesis_testing">Statistical hypothesis testing</a></li>
<li><a href="http://en.wikipedia.org/wiki/Statistical_inference">Statistical inference</a></li>
<li><a href="http://en.wikipedia.org/wiki/Sensitivity_and_specificity">Statistical sensitivity and specificity</a></li>
<li><a href="http://en.wikipedia.org/wiki/Statistical_significance">Statistical significance</a></li>
<li><a href="http://en.wikipedia.org/wiki/Statistics">Statistics</a></li>
<li><a href="http://en.wikipedia.org/wiki/Founders_of_statistics">Statistics, Founders of</a></li>
<li><a href="http://en.wikipedia.org/wiki/History_of_statistics">Statistics, History of</a></li>
<li><a href="https://en.wikipedia.org/wiki/Mathematical_statistics">Statistics, Mathematical</a></li>
<li><a href="http://en.wikipedia.org/wiki/Outline_of_statistics">Statistics, Outline of</a></li>
<li><a href="https://en.wikipedia.org/wiki/Philosophy_of_statistics">Statistics, Philosophy of</a></li>
<li><a href="https://en.wikipedia.org/wiki/Student%27s_t-test">Student&#8217;s t-test</a></li>
<li><a href="http://en.wikipedia.org/wiki/Systematic_error">Systematic error</a></li>
<li><a href="https://en.wikipedia.org/wiki/Trial_and_error">Trial and error</a></li>
<li><a href="https://en.wikipedia.org/wiki/John_Tukey">Turkey, John (1915-2000)</a></li>
<li><a href="http://en.wikipedia.org/wiki/Type_I_and_type_II_errors">Type-I and type-II errors</a></li>
<li><a href="https://en.wikipedia.org/wiki/Uncomfortable_science">Uncomfortable science</a></li>
<li><a href="http://en.wikipedia.org/wiki/Uniformitarianism">Uniformitarianism</a></li>
<li><a href="http://en.wikipedia.org/wiki/List_of_unsolved_problems_in_statistics">Unsolved problems in statistics, List of</a></li>
<li><a href="https://en.wikipedia.org/wiki/John_Venn">Venn, John (1834-1923)</a></li>
</ul>
<h3 id="others">Others</h3>
<ul>
<li><a href="http://errorstatistics.com/">errorstatistics.com</a> - Deborah Mayo&#8217;s blog</li>
<li><a href="http://statprob.com/encyclopedia/JohnGRAUNT.html">Graunt, John (1620-1674)</a> - statprob.com</li>
<li><a href="http://simplystatistics.org/2016/08/24/replication-crisis/">Peng, R. (2016). A Simple Explanation for the Replication Crisis in Science.</a> - simplystatistics.org</li>
</ul>
<!-- REFERENCES -->
<h2 id="references" class="unnumbered">References</h2>
<p>   </p>
<div id="refs" class="references">
<div id="ref-Aldrich_1997_RAFisher_and_the_making_of_maximum_likelihood">
<p>Aldrich, J. (1997). R. A. Fisher and the making of maximum likelihood 1912-1922. <em>Statistical Science</em>, <em>12</em>, 162&#8211;176.</p>
</div>
<div id="ref-Anderson_2008_The_End_of_Theory_The_data_deluge_makes">
<p>Anderson, C. (2008). The End of Theory: The data deluge makes the scientific method obsolete. <em>Wired</em>. June 23, 2008. <a href="https://www.wired.com/2008/06/pb-theory/" class="uri">https://www.wired.com/2008/06/pb-theory/</a></p>
</div>
<div id="ref-Asch_2018_Big_data_and_extreme_scale_computing_Pathways">
<p>Asch, M. et al. (2018). Big data and extreme-scale computing: Pathways to Convergence-Toward a shaping strategy for a future software and data ecosystem for scientific inquiry. <em>The International Journal of High Performance Computing Applications</em>, <em>32</em>, 435&#8211;479.</p>
</div>
<div id="ref-ATLAS_2012_Combined_search_for_the_Standard_Model_Higgs_boson">
<p>ATLAS Collaboration. (2012). Combined search for the Standard Model Higgs boson in <span class="math inline">\(pp\)</span> collisions at <span class="math inline">\(\sqrt{s}\)</span> = 7 TeV with the ATLAS detector. <em>Physical Review D</em>, <em>86</em>, 032003. <a href="https://arxiv.org/abs/1207.0319" class="uri">https://arxiv.org/abs/1207.0319</a></p>
</div>
<div id="ref-Benjamin_2017_Redefine_statistical_significance">
<p>Benjamin, D.J. et al. (2017). Redefine statistical significance. <em>PsyArXiv</em>. July 22, 2017. <a href="https://psyarxiv.com/mky9j/" class="uri">https://psyarxiv.com/mky9j/</a></p>
</div>
<div id="ref-Berger_2003_Could_Fisher_Jeffreys_and_Neyman_have_agreed_on">
<p>Berger, J. O. (2003). Could Fisher, Jeffreys and Neyman have agreed on testing? <em>Statistical Science</em>, <em>18</em>, 1&#8211;32.</p>
</div>
<div id="ref-Berger_1988_The_Likelihood_Principle">
<p>Berger, J. O. &amp; Wolpert, R. L. (1988). <em>The Likelihood Principle</em> (2nd ed.). Haywood, CA: The Institute of Mathematical Statistics.</p>
</div>
<div id="ref-Birnbaum_1962_On_the_foundations_of_statistical_inference">
<p>Birnbaum, A. (1962). On the foundations of statistical inference. <em>Journal of the American Statistical Association</em>, <em>57</em>, 269&#8211;326.</p>
</div>
<div id="ref-Carnap_1945_On_inductive_logic">
<p>Carnap, R. (1945). On inductive logic. <em>Philosophy of Science</em>, <em>12</em>, 72&#8211;97.</p>
</div>
<div id="ref-Carnap_1966_The_aim_of_inductive_logic">
<p>&#8212;&#8212;&#8212;. (1966). The aim of inductive logic. In <em>Studies in Logic and the Foundations of Mathematics Vol. 44</em> (pp. 303&#8211;318). Elsevier.</p>
</div>
<div id="ref-Carnap_1973_Notes_on_probability_and_induction">
<p>&#8212;&#8212;&#8212;. (1973). Notes on probability and induction. <em>Synthese</em>, <em>269</em>.</p>
</div>
<div id="ref-Cowan_1998_Statistical_Data_Analysis">
<p>Cowan, G. (1998). <em>Statistical Data Analysis</em>. Clarendon Press.</p>
</div>
<div id="ref-Cowan_2012_Discovery_sensitivity_for_a_counting_experiment">
<p>&#8212;&#8212;&#8212;. (2012). Discovery sensitivity for a counting experiment with background uncertainty. <a href="https://www.pp.rhul.ac.uk/~cowan/stat/notes/medsigNote.pdf" class="uri">https://www.pp.rhul.ac.uk/~cowan/stat/notes/medsigNote.pdf</a></p>
</div>
<div id="ref-Cowan_2016_Statistics">
<p>&#8212;&#8212;&#8212;. (2016). Statistics. In C. Patrignani <em>et al</em>. (Particle Data Group), <em>Chinese Physics C</em>, <em>40</em>, 100001. <a href="http://pdg.lbl.gov/2016/reviews/rpp2016-rev-statistics.pdf" class="uri">http://pdg.lbl.gov/2016/reviews/rpp2016-rev-statistics.pdf</a>.</p>
</div>
<div id="ref-Cowan_2011_Asymptotic_formulae_for_likelihood_based_tests">
<p>Cowan, G., Cranmer, K., Gross, E., &amp; Vitells, O. (2011). Asymptotic formulae for likelihood-based tests of new physics. <em>European Physical Journal C</em>, <em>71</em>, 1544. <a href="https://arxiv.org/abs/1007.1727" class="uri">https://arxiv.org/abs/1007.1727</a></p>
</div>
<div id="ref-Cramer_1946_A_contribution_to_the_theory_of_statistical">
<p>Cram&#233;r, H. (1946). A contribution to the theory of statistical estimation. <em>Skandinavisk Aktuarietidskrift</em>, <em>29</em>, 85&#8211;94.</p>
</div>
<div id="ref-Cranmer_2015_Practical_statistics_for_the_LHC">
<p>Cranmer, K. (2015). Practical statistics for the LHC. <a href="https://arxiv.org/abs/1503.07622" class="uri">https://arxiv.org/abs/1503.07622</a></p>
</div>
<div id="ref-DAgnolo_2019_Learning_New_Physics_from_a_Machine">
<p>D&#8217;Agnolo, R. T. &amp; Wulzer, A. (2019). Learning New Physics from a Machine. <em>Physical Review D</em>, <em>99</em>, 015014. <a href="https://arxiv.org/abs/1806.02350" class="uri">https://arxiv.org/abs/1806.02350</a></p>
</div>
<div id="ref-Edwards_1974_The_history_of_likelihood">
<p>Edwards, A. W. F. (1974). The history of likelihood. <em>International Statistical Review</em>, <em>42</em>, 9&#8211;15.</p>
</div>
<div id="ref-Evans_2013_What_does_the_proof_of_Birnbaums_theorem_prove">
<p>Evans, M. (2013). What does the proof of Birnbaum&#8217;s theorem prove? <a href="https://arxiv.org/abs/1302.5468" class="uri">https://arxiv.org/abs/1302.5468</a></p>
</div>
<div id="ref-Feldman_1998_A_unified_approach_to_the_classical_statistical">
<p>Feldman, G. J. &amp; Cousins, R. D. (1998). A unified approach to the classical statistical analysis of small signals. <em>Physical Review D</em>, <em>57</em>, 3873. <a href="https://arxiv.org/abs/physics/9711021" class="uri">https://arxiv.org/abs/physics/9711021</a></p>
</div>
<div id="ref-Fisher_1912_On_an_absolute_criterion_for_fitting_frequency">
<p>Fisher, R. A. (1912). On an absolute criterion for fitting frequency curves. <em>Statistical Science</em>, <em>12</em>, 39&#8211;41.</p>
</div>
<div id="ref-Fisher_1915_Frequency_distribution_of_the_values">
<p>&#8212;&#8212;&#8212;. (1915). Frequency distribution of the values of the correlation coefficient in samples of indefinitely large population. <em>Biometrika</em>, <em>10</em>, 507&#8211;521.</p>
</div>
<div id="ref-Fisher_1921_On_the_probable_error_of_a_coefficient">
<p>&#8212;&#8212;&#8212;. (1921). On the &#8220;probable error&#8221; of a coefficient of correlation deduced from a small sample. <em>Metron</em>, <em>1</em>, 1&#8211;32.</p>
</div>
<div id="ref-Fisher_1935_The_Design_of_Experiments">
<p>&#8212;&#8212;&#8212;. (1935). <em>The Design of Experiments</em>. Hafner.</p>
</div>
<div id="ref-Frechet_1943_Sur_lextension_de_certaines_evaluations">
<p>Fr&#233;chet, M. (1943). Sur l&#8217;extension de certaines &#233;valuations statistiques au cas de petits &#233;chantillons. <em>Revue de L&#8217;Institut International de Statistique</em>, <em>11</em>, 182&#8211;205.</p>
</div>
<div id="ref-Gandenberger_2015_A_new_proof_of_the_likelihood_principle">
<p>Gandenberger, G. (2015). A new proof of the likelihood principle, <em>British Journal for the Philosophy of Science</em>, <em>66</em>, 475&#8211;503.</p>
</div>
<div id="ref-Good_1988_The_interface_between_statistics_and_philosophy">
<p>Good, I. J. (1988). The interface between statistics and philosophy of science. <em>Statistical Science</em>, <em>3</em>, 386&#8211;397.</p>
</div>
<div id="ref-Hacking_1965_Logic_of_Statistical_Inference">
<p>Hacking, I. (1965). <em>Logic of Statistical Inference</em>. Cambridge University Press.</p>
</div>
<div id="ref-Hacking_1971_Jacques_Bernoullis_Art_of_conjecturing">
<p>&#8212;&#8212;&#8212;. (1971). Jacques Bernoulli&#8217;s Art of conjecturing. <em>The British Journal for the Philosophy of Science</em>, <em>22</em>, 209&#8211;229.</p>
</div>
<div id="ref-Hacking_2001_An_Introduction_to_Probability_and_Inductive_Logic">
<p>&#8212;&#8212;&#8212;. (2001). <em>An Introduction to Probability and Inductive Logic</em>. Cambridge University Press.</p>
</div>
<div id="ref-Hastie_2009_The_Elements_of_Statistical_Learning_Data_Mining">
<p>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em> (2nd ed.). Springer.</p>
</div>
<div id="ref-Huber_2007_Confirmation_and_induction">
<p>Huber, F. (2007). Confirmation and induction. <em>Internet Encyclopedia of Philosophy</em>. <a href="http://www.iep.utm.edu/conf-ind/" class="uri">http://www.iep.utm.edu/conf-ind/</a></p>
</div>
<div id="ref-Hume_2007_An_Enquiry_Concerning_Human_Understanding">
<p>Hume, D. (2007). <em>An Enquiry Concerning Human Understanding</em>. (P. Millican, Ed.). Oxford University Press. (Originally published in 1748).</p>
</div>
<div id="ref-James_2006_Statistical_Methods_in_Experimental_Particle">
<p>James, F. (2006). <em>Statistical Methods in Experimental Particle Physics</em>. World Scientific.</p>
</div>
<div id="ref-Kendall_1946_The_Advanced_Theory_of_Statistics_VolII">
<p>Kendall, M. G. (1946). <em>The Advanced Theory of Statistics, Vol.II</em>. London: Charles Griffin &amp; Company.</p>
</div>
<div id="ref-Leemis_2008_Univariate_distribution_relationships">
<p>Leemis, L. M. &amp; McQueston, J. T. (2008). Univariate distribution relationships. <em>The American Statistician</em>, <em>62</em>, 45&#8211;53.</p>
</div>
<div id="ref-Mayo_1981_In_defense_of_the_Neyman_Pearson_theory">
<p>Mayo, D. G. (1981). In defense of the Neyman-Pearson theory of confidence intervals. <em>Philosophy of Science</em>, <em>48</em>, 269&#8211;280.</p>
</div>
<div id="ref-Mayo_1996_Error_and_the_Growth_of_Experimental_Knowledge">
<p>&#8212;&#8212;&#8212;. (1996). <em>Error and the Growth of Experimental Knowledge</em>. Chicago University Press.</p>
</div>
<div id="ref-Mayo_2014_On_the_Birnbaum_Argument_for_the_Strong_Likelihood">
<p>&#8212;&#8212;&#8212;. (2014). On the Birnbaum Argument for the Strong Likelihood Principle, <em>Statistical Science</em>, <em>29</em>, 227&#8211;266.</p>
</div>
<div id="ref-Mayo_2018_Statistical_Inference_as_Severe_Testing_How">
<p>&#8212;&#8212;&#8212;. (2018). <em>Statistical Inference as Severe Testing: How to Get Beyond the Statistics Wars</em>. Cambridge University Press.</p>
</div>
<div id="ref-Neyman_1933_On_the_problem_of_the_most_efficient_tests">
<p>Neyman, J. &amp; Pearson, E. S. (1933). On the problem of the most efficient tests of statistical hypotheses. <em>Philosophical Transactions of the Royal Society A</em>, <em>231</em>, 289&#8211;337.</p>
</div>
<div id="ref-Peirce_1883_Studies_in_Logic">
<p>Peirce, C. S. (1883). <em>Studies in Logic</em>. Boston: Little, Brown, and Co.</p>
</div>
<div id="ref-Rao_1945_Information_and_the_accuracy_attainable">
<p>Rao, C. R. (1945). Information and the accuracy attainable in the estimation of statistical parameters. <em>Bulletin of the Calcutta Mathematical Society</em>, <em>37</em>, 81&#8211;91.</p>
</div>
<div id="ref-Rao_1947_Minimum_variance_and_the_estimation_of_several">
<p>&#8212;&#8212;&#8212;. (1947). Minimum variance and the estimation of several parameters. In <em>Mathematical Proceedings of the Cambridge Philosophical Society</em>. 43, 280&#8211;283. Cambridge University Press.</p>
</div>
<div id="ref-Reichenbach_1938_Experience_and_Prediction">
<p>Reichenbach, H. (1938). <em>Experience and Prediction</em>. University of Chicago Press.</p>
</div>
<div id="ref-Reichenbach_1940_On_the_justification_of_induction">
<p>&#8212;&#8212;&#8212;. (1940). On the justification of induction. <em>The Journal of Philosophy</em>, <em>37</em>, 97&#8211;103.</p>
</div>
<div id="ref-Salmon_1963_On_vindicating_induction">
<p>Salmon, W. C. (1963). On vindicating induction. <em>Philosophy of Science</em>, <em>30</em>, 252&#8211;261.</p>
</div>
<div id="ref-Salmon_1966_The_Foundations_of_Scientific_Inference">
<p>&#8212;&#8212;&#8212;. (1966). <em>The Foundations of Scientific Inference</em>. University of Pittsburgh Press.</p>
</div>
<div id="ref-Salmon_1967_Carnaps_inductive_logic">
<p>&#8212;&#8212;&#8212;. (1967). Carnap&#8217;s inductive logic. <em>The Journal of Philosophy</em>, <em>64</em>, 725&#8211;739.</p>
</div>
<div id="ref-Salmon_1991_Hans_Reichenbachs_vindication_of_induction">
<p>&#8212;&#8212;&#8212;. (1991). Hans Reichenbach&#8217;s vindication of induction. <em>Erkenntnis</em>, <em>35</em>, 99&#8211;122.</p>
</div>
<div id="ref-Savage_1954_The_Foundations_of_Statistics">
<p>Savage, L. J. (1954). <em>The Foundations of Statistics</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-Sinervo_2002_Signal_significance_in_particle_physics">
<p>Sinervo, P. (2002). Signal significance in particle physics. In M. Whalley &amp; L. Lyons (Eds.), <em>Proceedings of the Conference on Advanced Statistical Techniques in Particle Physics</em>. Durham, UK: Institute of Particle Physics Phenomenology. <a href="https://arxiv.org/abs/hep-ex/0208005v1" class="uri">https://arxiv.org/abs/hep-ex/0208005v1</a></p>
</div>
<div id="ref-Sinervo_2003_Definition_and_treatment_of_systematic">
<p>&#8212;&#8212;&#8212;. (2003). Definition and treatment of systematic uncertainties in high energy physics and astrophysics. In Lyons L., Mount R., &amp; R. Reitmeyer (Eds.), <em>Proceedings of the Conference on Statistical Problems in Particle Physics, Astrophysics, and Cosmology (PhyStat2003)</em> (pp. 122&#8211;129). Stanford Linear Accelerator Center. <a href="https://www.slac.stanford.edu/econf/C030908/papers/TUAT004.pdf" class="uri">https://www.slac.stanford.edu/econf/C030908/papers/TUAT004.pdf</a></p>
</div>
<div id="ref-Venn_1888_The_Logic_of_Chance">
<p>Venn, J. (1888). <em>The Logic of Chance</em>. London: MacMillan and Co. (Originally published in 1866).</p>
</div>
<div id="ref-Vickers_2014_The_Problem_of_Induction">
<p>Vickers, J. (2014). The Problem of Induction. <em>Stanford Encyclopedia of Philosophy</em>. <a href="https://stanford.library.sydney.edu.au/archives/sum2016/entries/induction-problem/" class="uri">https://stanford.library.sydney.edu.au/archives/sum2016/entries/induction-problem/</a></p>
</div>
<div id="ref-Wald_1943_Tests_of_statistical_hypotheses_concerning_several">
<p>Wald, A. (1943). Tests of statistical hypotheses concerning several parameters when the number of observations is large. <em>Transactions of the American Mathematical Society</em>, <em>54</em>, 426&#8211;482.</p>
</div>
<div id="ref-Wasserman_2003_All_of_Statistics_A_Concise_Course_in_Statistical">
<p>Wasserman, L. (2003). <em>All of Statistics: A Concise Course in Statistical Inference</em>. Springer.</p>
</div>
<div id="ref-Wasserstein_2016_The_ASAs_statement_on_p_values_Context_process">
<p>Wasserstein, R. L. &amp; Lazar, N. A. (2016). The ASA&#8217;s statement on p-values: Context, process, and purpose. <em>American Statistician</em>, <em>70</em>, 129&#8211;133.</p>
</div>
<div id="ref-Weintraub_1995_What_was_Humes_contribution_to_the_problem">
<p>Weintraub, R. (1995). What was Hume&#8217;s contribution to the problem of induction? <em>The Philosophical Quarterly</em>, <em>45</em>, 460&#8211;470.</p>
</div>
<div id="ref-Weisberg_2019_Odds__Ends_Introducing_Probability__Decision">
<p>Weisberg, J. (2019). <em>Odds &amp; Ends: Introducing Probability &amp; Decision with a Visual Emphasis</em>. <a href="https://jonathanweisberg.org/vip/" class="uri">https://jonathanweisberg.org/vip/</a></p>
</div>
<div id="ref-Wilks_1938_The_large_sample_distribution_of_the_likelihood">
<p>Wilks, S. S. (1938). The large-sample distribution of the likelihood ratio for testing composite hypotheses. <em>The Annals of Mathematical Statistics</em>, <em>9</em>, 60&#8211;62.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><span class="citation">Hume (2007)</span>.<a href="#fnref1">&#8617;</a></p></li>
<li id="fn2"><p><span class="citation">Weintraub (1995)</span>.<a href="#fnref2">&#8617;</a></p></li>
<li id="fn3"><p><span class="citation">Reichenbach (1938)</span> and <span class="citation">Reichenbach (1940)</span>.<a href="#fnref3">&#8617;</a></p></li>
<li id="fn4"><p><span class="citation">Carnap (1945)</span>, <span class="citation">Carnap (1966)</span>, <span class="citation">Carnap (1973)</span>.<a href="#fnref4">&#8617;</a></p></li>
<li id="fn5"><p><span class="citation">Salmon (1963)</span>, <span class="citation">Salmon (1966)</span>, <span class="citation">Salmon (1967)</span>, <span class="citation">Salmon (1991)</span>.<a href="#fnref5">&#8617;</a></p></li>
<li id="fn6"><p><span class="citation">Good (1988)</span>.<a href="#fnref6">&#8617;</a></p></li>
<li id="fn7"><p><span class="citation">Hacking (2001)</span>.<a href="#fnref7">&#8617;</a></p></li>
<li id="fn8"><p><span class="citation">Huber (2007)</span>.<a href="#fnref8">&#8617;</a></p></li>
<li id="fn9"><p><span class="citation">Vickers (2014)</span>.<a href="#fnref9">&#8617;</a></p></li>
<li id="fn10"><p><span class="citation">Cowan (1998)</span> and <span class="citation">Cowan (2016)</span>.<a href="#fnref10">&#8617;</a></p></li>
<li id="fn11"><p><span class="citation">Edwards (1974)</span>, p.&#160;9.<a href="#fnref11">&#8617;</a></p></li>
<li id="fn12"><p><span class="citation">Hacking (1971)</span>.<a href="#fnref12">&#8617;</a></p></li>
<li id="fn13"><p><span class="citation">Venn (1888)</span>.<a href="#fnref13">&#8617;</a></p></li>
<li id="fn14"><p><span class="citation">Peirce (1883)</span>, p.&#160;126&#8211;181.<a href="#fnref14">&#8617;</a></p></li>
<li id="fn15"><p><span class="citation">Fisher (1912)</span>.<a href="#fnref15">&#8617;</a></p></li>
<li id="fn16"><p><span class="citation">Fisher (1915)</span>.<a href="#fnref16">&#8617;</a></p></li>
<li id="fn17"><p><span class="citation">Fisher (1921)</span>.<a href="#fnref17">&#8617;</a></p></li>
<li id="fn18"><p><span class="citation">Edwards (1974)</span>.<a href="#fnref18">&#8617;</a></p></li>
<li id="fn19"><p><span class="citation">Birnbaum (1962)</span>.<a href="#fnref19">&#8617;</a></p></li>
<li id="fn20"><p><span class="citation">Hacking (1965)</span>.<a href="#fnref20">&#8617;</a></p></li>
<li id="fn21"><p><span class="citation">Berger &amp; Wolpert (1988)</span>.<a href="#fnref21">&#8617;</a></p></li>
<li id="fn22"><p><span class="citation">Evans (2013)</span>.<a href="#fnref22">&#8617;</a></p></li>
<li id="fn23"><p><span class="citation">Mayo (2014)</span>.<a href="#fnref23">&#8617;</a></p></li>
<li id="fn24"><p><span class="citation">Gandenberger (2015)</span>.<a href="#fnref24">&#8617;</a></p></li>
<li id="fn25"><p><span class="citation">Hacking (1965)</span>.<a href="#fnref25">&#8617;</a></p></li>
<li id="fn26"><p><span class="citation">Berger (2003)</span>.<a href="#fnref26">&#8617;</a></p></li>
<li id="fn27"><p><span class="citation">Mayo (1996)</span>.<a href="#fnref27">&#8617;</a></p></li>
<li id="fn28"><p><span class="citation">Mayo (1981)</span>.<a href="#fnref28">&#8617;</a></p></li>
<li id="fn29"><p><span class="citation">Mayo (2018)</span>.<a href="#fnref29">&#8617;</a></p></li>
<li id="fn30"><p><span class="citation">Kendall (1946)</span>.<a href="#fnref30">&#8617;</a></p></li>
<li id="fn31"><p><span class="citation">James (2006)</span>.<a href="#fnref31">&#8617;</a></p></li>
<li id="fn32"><p><span class="citation">Cowan (1998)</span> and <span class="citation">Cowan (2016)</span>.<a href="#fnref32">&#8617;</a></p></li>
<li id="fn33"><p><span class="citation">Cranmer (2015)</span>.<a href="#fnref33">&#8617;</a></p></li>
<li id="fn34"><p><span class="citation">Weisberg (2019)</span>.<a href="#fnref34">&#8617;</a></p></li>
<li id="fn35"><p><span class="citation">Aldrich (1997)</span>.<a href="#fnref35">&#8617;</a></p></li>
<li id="fn36"><p><span class="citation">Fr&#233;chet (1943)</span>, <span class="citation">Cram&#233;r (1946)</span>, <span class="citation">Rao (1945)</span>, and <span class="citation">Rao (1947)</span>.<a href="#fnref36">&#8617;</a></p></li>
<li id="fn37"><p><span class="citation">Neyman &amp; Pearson (1933)</span>.<a href="#fnref37">&#8617;</a></p></li>
<li id="fn38"><p><span class="citation">Wilks (1938)</span>.<a href="#fnref38">&#8617;</a></p></li>
<li id="fn39"><p><span class="citation">Wald (1943)</span>.<a href="#fnref39">&#8617;</a></p></li>
<li id="fn40"><p><span class="citation">Sinervo (2002)</span> and <span class="citation">Cowan (2012)</span>.<a href="#fnref40">&#8617;</a></p></li>
<li id="fn41"><p><span class="citation">Feldman &amp; Cousins (1998)</span>.<a href="#fnref41">&#8617;</a></p></li>
<li id="fn42"><p><span class="citation">Cowan, Cranmer, Gross, &amp; Vitells (2011)</span>.<a href="#fnref42">&#8617;</a></p></li>
<li id="fn43"><p><span class="citation">Sinervo (2003)</span>.<a href="#fnref43">&#8617;</a></p></li>
<li id="fn44"><p><span class="citation">Fisher (1935)</span>, p.&#160;13&#8211;14.<a href="#fnref44">&#8617;</a></p></li>
<li id="fn45"><p><span class="citation">Wasserstein &amp; Lazar (2016)</span>.<a href="#fnref45">&#8617;</a></p></li>
<li id="fn46"><p><span class="citation">Benjamin, D.J. et al. (2017)</span>.<a href="#fnref46">&#8617;</a></p></li>
<li id="fn47"><p><span class="citation">Hastie, Tibshirani, &amp; Friedman (2009)</span>.<a href="#fnref47">&#8617;</a></p></li>
<li id="fn48"><p><span class="citation">Asch, M. et al. (2018)</span>.<a href="#fnref48">&#8617;</a></p></li>
<li id="fn49"><p><span class="citation">D&#8217;Agnolo &amp; Wulzer (2019)</span>.<a href="#fnref49">&#8617;</a></p></li>
<li id="fn50"><p><span class="citation">Anderson (2008)</span>.<a href="#fnref50">&#8617;</a></p></li>
<li id="fn51"><p><span class="citation">Leemis &amp; McQueston (2008)</span>.<a href="#fnref51">&#8617;</a></p></li>
<li id="fn52"><p><span class="citation">Wasserman (2003)</span>.<a href="#fnref52">&#8617;</a></p></li>
<li id="fn53"><p><span class="citation">Savage (1954)</span>.<a href="#fnref53">&#8617;</a></p></li>
</ol>
</div>

</div> <!-- end pagecontainer -->
</div> <!-- end mainbody -->

<div class="nav">
<ul>
    <li> <a href="./">&#8634;&nbsp;Contents</a> </li>
    <li> <a href="#site_header">&#8613;&nbsp;Top</a> </li>
    <li> <a href="./scientific-method.html">&#8612;&nbsp;Previous</a> </li>
    <li> <a href="./scientific-realism.html">&#8614;&nbsp;Next</a> </li>
</ul>
</div>

<!--
<div id="afterbody">
</div>
-->

<div id="site_footer">
  <div class="signature">
    <p><i>Ryan Reece</i></p>
    <p><img class="email" src="img/my-email-alt-blue.png" alt="my email address"/></p>
    <p>Sun Jan 19, 2020</p>
  </div>
  <div class="license">
    <p><span class="copy-left">&#169;</span> 2014-2019 <a href="http://rreece.github.io/">Ryan Reece</a>. Licensed for sharing under <a href="http://creativecommons.org/licenses/by/4.0/">CC-BY-4.0</a>.</p>
    <p>Made with <a href="https://github.com/rreece/markdown-memo">markdown-memo</a>.</p>
  </div>
  <div style="clear:both;"></div>
</div>

<!-- disqus stuff -->
<div id="disqus_stuff">
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'ryans-outline-of-philosophy';
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript><p>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></p></noscript>

<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'ryans-outline-of-philosophy';
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</div> <!-- end disqus_stuff -->

</body>
</html>

