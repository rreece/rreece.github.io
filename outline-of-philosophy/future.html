<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
      "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<!--- Google Analytics Tracking stuff  -->
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-QD5EP98QH0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-QD5EP98QH0');
</script>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Style-Type" content="text/css" />
<meta name="generator" content="pandoc" />
<meta name="author" content="Ryan Reece" />
<meta name="date" content="Sat Jun 08, 2024" />
<title>Futures studies - Ryan's Outline of Philosophy</title>
<meta name="description" content="Ryan Reece&#x2019;s outline of philosophy" />
<link rel="stylesheet" type="text/css" href="templates/markdown-memo-alt-blue-dark.css"/>
<link rel="icon" type="image/png" href="img/markdown-favicon-196x196.png" />

<!--- MathJax stuff -->
<script type="text/javascript" src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });
</script>

<!--- toggle_more function  -->
<script type="text/javascript">
    //<![CDATA[
    function toggle_more(objID) {
        if (!document.getElementById) return;
        var ob = document.getElementById(objID).style;
        ob.display = (ob.display == 'block')?'none':'block';
        var ob2 = document.getElementById('link:'+objID);
        ob2.className = (ob2.className == 'open') ? 'closed' : 'open';
    }
    //]]>
</script>

</head>

<body>

<div id="site_header">
    <a href="./">Ryan&#x2019;s Outline of Philosophy</a>
</div>

<!--
<div id="beforebody">
</div>
-->

<div class="nav">
<ul>
    <li> <a href="./">&#8634;&nbsp;Contents</a> </li>
    <li> <a href="#site_footer">&#8615;&nbsp;Bottom</a> </li>
    <li> <a href="./human-condition.html">&#8612;&nbsp;Previous</a> </li>
</ul>
</div>

<div id="mainbody">
<div id="pagecontainer">

<h1 id="futures-studies">Futures studies</h1>
<p>Philosophy of the future&#x2014;Where are we going?</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<h3 class="unnumbered" id="contents">Contents</h3>
<ol type="1">
<li><a href="future.html#risk">Risk</a>
<ol type="1">
<li><a href="future.html#limits-to-growth">Limits to growth</a></li>
<li><a href="future.html#existential-threats">Existential threats</a></li>
<li><a href="future.html#fermi-paradox">Fermi paradox</a></li>
</ol></li>
<li><a href="future.html#technological-growth">Technological growth</a>
<ol type="1">
<li><a href="future.html#future-of-computing">Future of computing</a></li>
<li><a href="future.html#future-of-the-internet">Future of the internet</a></li>
<li><a href="future.html#simulation-argument">Simulation argument</a></li>
</ol></li>
<li><a href="future.html#artificial-intelligence">Artificial intelligence</a>
<ol type="1">
<li><a href="future.html#outlook">Outlook</a></li>
<li><a href="future.html#risks">Risks</a></li>
</ol></li>
<li><a href="future.html#transhumanism">Transhumanism</a></li>
<li><a href="future.html#my-thoughts">My thoughts</a></li>
<li><a href="future.html#annotated-bibliography">Annotated bibliography</a>
<ol type="1">
<li><a href="future.html#bostrom-n.-2002.-anthropic-bias-observation-selection-effects-in-science-and-philosophy.">Bostrom, N. (2002). Anthropic Bias: Observation selection effects in science and philosophy.</a></li>
<li><a href="future.html#bostrom-n.-2003.-are-you-living-in-a-computer-simulation">Bostrom, N. (2003). Are You Living in a Computer Simulation?</a></li>
<li><a href="future.html#bostrom-n.-2014.-superintelligence-paths-dangers-strategies.">Bostrom, N. (2014). Superintelligence: Paths, Dangers, Strategies.</a></li>
<li><a href="future.html#more-articles-to-do">More articles to do</a></li>
</ol></li>
<li><a href="future.html#links-and-encyclopedia-articles">Links and encyclopedia articles</a>
<ol type="1">
<li><a href="future.html#sep">SEP</a></li>
<li><a href="future.html#iep">IEP</a></li>
<li><a href="future.html#wikipedia">Wikipedia</a></li>
<li><a href="future.html#others">Others</a></li>
<li><a href="future.html#videos">Videos</a></li>
</ol></li>
<li><a href="future.html#references">References</a></li>
</ol>
<h2 id="risk">Risk</h2>
<h3 id="limits-to-growth">Limits to growth</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/The_Limits_to_Growth"><em>The Limits to Growth</em> (1972)</a></li>
</ul>
<p>See also:</p>
<ul>
<li><a href="ethics.html#ecology">Ecology</a> in the <a href="ethics.html">Outline on Ethics</a>.</li>
</ul>
<h3 id="existential-threats">Existential threats</h3>
<ul>
<li>Bostrom, N. (2013). <a href="https://www.existential-risk.org/concept.pdf">Existential risk prevention as global priority</a>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
<li>Climate change</li>
<li>WMDs</li>
<li>Pandemics</li>
<li>&#x2026;</li>
<li><a href="https://en.wikipedia.org/wiki/Doomsday_argument">Doomsday argument</a></li>
<li>Hanson, R. (1998). <a href="https://web.archive.org/web/20050405210231/http://hanson.gmu.edu/nodoom.html">Critiquing the doomsday argument</a>.</li>
<li>Baum, S.D. et al.&#xA0;(2019). Long-term trajectories of human civilization.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></li>
<li>Bostrom, N. (2019). <a href="https://nickbostrom.com/papers/vulnerable.pdf">The vulnerable world hypothesis</a>.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></li>
</ul>
<h3 id="fermi-paradox">Fermi paradox</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Fermi_paradox">Fermi paradox</a></li>
<li>Freitas, R.A. (1983). <a href="http://www.rfreitas.com/Astro/ResolvingFermi1983.htm">Extraterrestrial intelligence in the solar system: Resolving the Fermi paradox</a>.</li>
<li>Bostrom, N. (2002). <em>Anthropic Bias: Observation selection effects in science and philosophy</em>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></li>
<li>Sandberg, A., Drexler, E., &amp; Ord, T. (2018). <a href="https://arxiv.org/abs/1806.02404">Dissolving the Fermi paradox</a>.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></li>
<li>Hanson, R., Martin, D., McCarter, C., &amp; Paulson, J. (2021). <a href="https://iopscience.iop.org/article/10.3847/1538-4357/ac2369">If loud aliens explain human earliness, quiet aliens are also rare</a>.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></li>
<li>Wong, M.L. &amp; Bartlett, S. (2022). <a href="https://royalsocietypublishing.org/doi/full/10.1098/rsif.2022.0029">Asymptotic burnout and homeostatic awakening: A possible solution to the Fermi paradox?</a><a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></li>
</ul>
<h2 id="technological-growth">Technological growth</h2>
<h3 id="future-of-computing">Future of computing</h3>
<ul>
<li>Feynman, R.P. (1959). <a href="https://calteches.library.caltech.edu/1976/1/1960Bottom.pdf">There&#x2019;s plenty of room at the bottom</a>.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></li>
<li>Vinge, V. (1993). <a href="https://edoras.sdsu.edu/~vinge/misc/singularity.html">The coming technological singularity</a>.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></li>
</ul>
<p>See also:</p>
<ul>
<li><a href="human-condition.html#industrial-revolution">Industrial Revolution</a> in the <a href="human-condition.html">Outline on the human condition</a>.</li>
<li><a href="future.html#artificial-intelligence">Artificial intelligence</a></li>
</ul>
<h3 id="future-of-the-internet">Future of the internet</h3>
<ul>
<li>Clegg, N. (2022). <a href="https://nickclegg.medium.com/making-the-metaverse-what-it-is-how-it-will-be-built-and-why-it-matters-3710f7570b04">Making the metaverse: What it is, how it will be built, and why it matters</a>.</li>
</ul>
<figure>
<img src="img/chatgpt-on-track-to-surpass-100-million-users-faster.png" id="fig:chatgpt-on-track-to-surpass-100-million-users-faster" alt="Figure 1: ChatGPT has had faster user growth than any other app (source: yahoo!finance, Feb.&#xA0;2023)." /><figcaption aria-hidden="true">Figure 1: ChatGPT has had faster user growth than any other app (source: <a href="https://finance.yahoo.com/news/chatgpt-on-track-to-surpass-100-million-users-faster-than-tiktok-or-instagram-ubs-214423357.html">yahoo!finance</a>, Feb.&#xA0;2023).</figcaption>
</figure>
<h3 id="simulation-argument">Simulation argument</h3>
<ul>
<li>Simulation argument<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> and patch<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></li>
<li><a href="https://en.wikipedia.org/wiki/Simulation_hypothesis">Simulation hypothesis</a></li>
</ul>
<h2 id="artificial-intelligence">Artificial intelligence</h2>
<h3 id="outlook">Outlook</h3>
<ul>
<li>Feynman, R.P. (1985). Talk: <a href="https://www.youtube.com/watch?v=ipRvjS7q1DI">Can machines think?</a></li>
<li>Russell &amp; Norvig<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a></li>
<li>Bostrom, N. (2014). <em>Superintelligence: Paths, Dangers, Strategies</em>.<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></li>
<li>Armstrong, S., Sotala, K., &amp; OhEigeartaigh, S. S. (2014). <a href="https://www.fhi.ox.ac.uk/wp-content/uploads/FAIC.pdf">The errors, insights and lessons of famous AI predictions&#x2013;and what they mean for the future</a>.<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a></li>
<li>Urban, T. (2015). <a href="https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html">The AI Revolution: The Road to Superintelligence</a>.<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a></li>
<li>Marcus, G. (2018). <a href="https://arxiv.org/abs/1801.00631">Deep learning: A critical appraisal</a>.<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a></li>
<li>Gwern. (2020). <a href="https://www.gwern.net/Scaling-hypothesis#scaling-hypothesis">The scaling hypothesis</a>.</li>
<li>Carroll, S. &amp; Russell, S. (2020). Video: <a href="https://www.youtube.com/watch?v=txGYG60TICA">Stuart Russell on making artificial intelligence compatible with humans</a>. Mindscape 94.
<ul>
<li>Russell: AI gives us the Midas touch</li>
</ul></li>
<li>Zhang, D. et al.&#xA0;(2021). <a href="https://arxiv.org/abs/2103.06312">The AI Index 2021 Annual Report</a>.<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a></li>
<li>Zhang, D. et al.&#xA0;(2022). <a href="https://aiindex.stanford.edu/wp-content/uploads/2022/03/2022-AI-Index-Report_Master.pdf">The AI Index 2022 Annual Report</a>.<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></li>
<li>Marcus, G. (2022). <a href="https://nautil.us/deep-learning-is-hitting-a-wall-14467/">Deep learning is hitting a wall: What would it take for artificial intelligence to make real progress?</a></li>
<li>Benaich, N. &amp; Hogarth, I. (2022). <a href="https://www.stateof.ai/2022-report-launch.html">State of AI Report 2022</a>.</li>
<li>Cotra, A. (2022). <a href="https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines">Two-year update on my personal AI timelines</a>.</li>
<li>Steinhardt, J. (2023). <a href="https://bounded-regret.ghost.io/forecasting-math-and-mmlu-in-2023/">Forecasting ML Benchmarks in 2023</a>.</li>
<li>Future of Life Institute. (2023). <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">Pause giant AI experiments: An open letter</a>.</li>
<li>Future of Life Institute. (2023). <a href="https://futureoflife.org/wp-content/uploads/2023/04/FLI_Policymaking_In_The_Pause.pdf">Policymaking in the Pause: What can policymakers do now to combat risks from advanced AI systems?</a>.</li>
<li>Altman, S. (2023). <a href="https://openai.com/blog/planning-for-agi-and-beyond">Planning for AGI and beyond</a>.</li>
<li>Bubeck, S. et al.&#xA0;(2023). <a href="https://arxiv.org/abs/2303.12712">Sparks of Artificial General Intelligence: Early experiments with GPT-4</a>.<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a></li>
<li>Maslej, N. et al.&#xA0;(2023). <a href="https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI_AI-Index-Report_2023.pdf">The AI Index 2023 Annual Report</a>.<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a></li>
<li>Maslej, N. et al.&#xA0;(2024). <a href="https://aiindex.stanford.edu/wp-content/uploads/2024/05/HAI_AI-Index-Report-2024.pdf">The AI Index 2024 Annual Report</a>.<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a></li>
<li>Aschenbrenner, L. (2024). <a href="https://situational-awareness.ai/wp-content/uploads/2024/06/situationalawareness.pdf">Situational Awareness: The decade ahead</a>.<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a></li>
</ul>
<p>See also:</p>
<ul>
<li><a href="statistics.html#deep-learning">Deep learning</a> in the <a href="statistics.html">Outline on the philosophy of statistics</a>.</li>
<li><a href="mind.html#artificial-intelligence-and-mind">Artificial intelligence and mind</a></li>
</ul>
<h3 id="risks">Risks</h3>
<ul>
<li>Jeremy Howard warning about the abilities of models like GPT-2:</li>
</ul>
<blockquote>
<p>We have the technology to totally fill Twitter, email, and the web up with reasonable-sounding, context-appropriate prose, which would drown out all other speech and be impossible to filter.<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a></p>
</blockquote>
<ul>
<li>Gabriel, I. et al.&#xA0;(DeepMind). (2024). <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/ethics-of-advanced-ai-assistants/the-ethics-of-advanced-ai-assistants-2024-i.pdf">The ethics of advanced AI assistants</a>.<a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a></li>
</ul>
<h2 id="transhumanism">Transhumanism</h2>
<ul>
<li>Nietzsche, F. (1883). <em>Thus Spoke Zarathustra</em>.
<ul>
<li>&#xDC;bermensch</li>
</ul></li>
<li>Haldane, J.B.S. (1924). <a href="http://bactra.org/Daedalus.html">Daedalus; or, Science and the Future</a>.</li>
<li>Russell, B. (1924). <a href="http://bactra.org/Icarus.html">Icarus, or the future of science</a>.</li>
<li>Huxley, Julian (1957). <a href="https://web.archive.org/web/20160625132722/http://www.transhumanism.org/index.php/WTA/more/huxley">Transhumanism</a>.</li>
<li>Bostrom, N. (2005). <a href="https://www.nickbostrom.com/fable/dragon.html">The fable of the dragon-tyrant</a>.<a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a></li>
</ul>
<h2 id="my-thoughts">My thoughts</h2>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<h2 id="annotated-bibliography">Annotated bibliography</h2>
<div class="clickmore">
<a id="link:annotated_bibliography" class="closed" onclick="toggle_more('annotated_bibliography')"> Click to show annotated bibliography </a>
</div>
<div id="annotated_bibliography" class="more">
<h3 id="bostrom-n.-2002.-anthropic-bias-observation-selection-effects-in-science-and-philosophy.">Bostrom, N. (2002). Anthropic Bias: Observation selection effects in science and philosophy.</h3>
<ul>
<li>TODO.</li>
</ul>
<h4 id="my-thoughts-1">My thoughts</h4>
<ul>
<li>TODO.</li>
</ul>
<hr />
<h3 id="bostrom-n.-2003.-are-you-living-in-a-computer-simulation">Bostrom, N. (2003). Are You Living in a Computer Simulation?</h3>
<ul>
<li>TODO.</li>
</ul>
<h4 id="my-thoughts-2">My thoughts</h4>
<ul>
<li>TODO.</li>
</ul>
<hr />
<h3 id="bostrom-n.-2014.-superintelligence-paths-dangers-strategies.">Bostrom, N. (2014). Superintelligence: Paths, Dangers, Strategies.</h3>
<ul>
<li>TODO.</li>
</ul>
<h4 id="my-thoughts-3">My thoughts</h4>
<ul>
<li>TODO.</li>
</ul>
<hr />
<h3 id="more-articles-to-do">More articles to do</h3>
<ul>
<li>TODO.</li>
</ul>
</div>
<h2 id="links-and-encyclopedia-articles">Links and encyclopedia articles</h2>
<div class="clickmore">
<a id="link:encyclopedia_articles" class="closed" onclick="toggle_more('encyclopedia_articles')"> Click to show links </a>
</div>
<div id="encyclopedia_articles" class="more">
<h3 id="sep">SEP</h3>
<h3 id="iep">IEP</h3>
<h3 id="wikipedia">Wikipedia</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Doomsday_argument">Doomsday argument</a></li>
<li><a href="https://en.wikipedia.org/wiki/Simulation_hypothesis">Simulation hypothesis</a></li>
<li><a href="https://en.wikipedia.org/wiki/The_Limits_to_Growth"><em>The Limits to Growth</em> (1972)</a></li>
</ul>
<h3 id="others">Others</h3>
<ul>
<li><a href="http://www.preposterousuniverse.com/blog/2016/08/22/maybe-we-do-not-live-in-a-simulation-the-resolution-conundrum/">Carroll, S. (2016). Maybe we do not live in a computer simulation</a></li>
</ul>
<h3 id="videos">Videos</h3>
</div>
<!-- REFERENCES -->
<h2 id="references">References</h2>
<p></p>
<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="doc-bibliography">
<div id="ref-Armstrong_2014_The_errors_insights_and_lessons_of_famous_AI" class="csl-entry" role="doc-biblioentry">
Armstrong, S., Sotala, K., &amp; OhEigeartaigh, S. S. (2014). <span class="nocase">The errors, insights and lessons of famous AI predictions&#x2013;and what they mean for the future.</span> <em>Journal of Experimental &amp; Theoretical Artificial Intelligence</em>, <em><span>26</span></em>, 317&#x2013;342. <a href="https://www.fhi.ox.ac.uk/wp-content/uploads/FAIC.pdf">https://www.fhi.ox.ac.uk/wp-content/uploads/FAIC.pdf</a>
</div>
<div id="ref-Aschenbrenner_2024_Situational_Awareness_The_decade_ahead" class="csl-entry" role="doc-biblioentry">
Aschenbrenner, L. (2024). <span class="nocase">Situational Awareness: The decade ahead</span>. <a href="https://situational-awareness.ai/wp-content/uploads/2024/06/situationalawareness.pdf">https://situational-awareness.ai/wp-content/uploads/2024/06/situationalawareness.pdf</a>
</div>
<div id="ref-Baum_2019_Long_term_trajectories_of_human_civilization" class="csl-entry" role="doc-biblioentry">
Baum, S.D. et al. (2019). <span class="nocase">Long-term trajectories of human civilization.</span> <em>Foresight</em>, <em><span>21</span></em>, 55&#x2013;83.
</div>
<div id="ref-Bostrom_2002_Anthropic_Bias_Observation_selection_effects" class="csl-entry" role="doc-biblioentry">
Bostrom, N. (2002). <em><span class="nocase">Anthropic Bias: Observation selection effects in science and philosophy</span></em>. <span>Routledge</span>.
</div>
<div id="ref-Bostrom_2003_Are_you_living_in_a_computer_simulation" class="csl-entry" role="doc-biblioentry">
&#x2014;&#x2014;&#x2014;. (2003). <span class="nocase">Are you living in a computer simulation?</span> <em>Philosophical Quarterly</em>, <em><span>53</span></em>, 243&#x2013;255.
</div>
<div id="ref-Bostrom_2005_The_fable_of_the_dragon_tyrant" class="csl-entry" role="doc-biblioentry">
&#x2014;&#x2014;&#x2014;. (2005). <span class="nocase">The fable of the dragon-tyrant.</span> <em>Journal of Medical Ethics</em>, <em><span>31</span></em>, 273&#x2013;277. <a href="https://www.nickbostrom.com/fable/dragon.html">https://www.nickbostrom.com/fable/dragon.html</a>
</div>
<div id="ref-Bostrom_2011_A_patch_for_the_simulation_argument" class="csl-entry" role="doc-biblioentry">
&#x2014;&#x2014;&#x2014;. (2011). <span class="nocase">A patch for the simulation argument.</span> <em>Analysis</em>, <em><span>71</span></em>, 54&#x2013;61.
</div>
<div id="ref-Bostrom_2013_Existential_risk_prevention_as_global_priority" class="csl-entry" role="doc-biblioentry">
&#x2014;&#x2014;&#x2014;. (2013). <span class="nocase">Existential risk prevention as global priority.</span> <em>Global Policy</em>, <em><span>4</span></em>, 15&#x2013;31. <a href="https://www.existential-risk.org/concept.pdf">https://www.existential-risk.org/concept.pdf</a>
</div>
<div id="ref-Bostrom_2014_Superintelligence_Paths_Dangers_Strategies" class="csl-entry" role="doc-biblioentry">
&#x2014;&#x2014;&#x2014;. (2014). <em><span>Superintelligence: Paths, Dangers, Strategies</span></em>. <span>Oxford University Press</span>.
</div>
<div id="ref-Bostrom_2019_The_vulnerable_world_hypothesis" class="csl-entry" role="doc-biblioentry">
&#x2014;&#x2014;&#x2014;. (2019). <span class="nocase">The vulnerable world hypothesis,</span>. <em>Global Policy</em>, <em><span>10</span></em>, 455&#x2013;476. <a href="https://nickbostrom.com/papers/vulnerable.pdf">https://nickbostrom.com/papers/vulnerable.pdf</a>
</div>
<div id="ref-Bubeck_2023_Sparks_of_Artificial_General_Intelligence_Early" class="csl-entry" role="doc-biblioentry">
Bubeck, S. et al. (2023). <span class="nocase">Sparks of Artificial General Intelligence: Early experiments with GPT-4</span>. <a href="https://arxiv.org/abs/2303.12712">https://arxiv.org/abs/2303.12712</a>
</div>
<div id="ref-Feynman_1959_Theres_plenty_of_room_at_the_bottom" class="csl-entry" role="doc-biblioentry">
Feynman, R. P. (1959). <span class="nocase">There&#x2019;s plenty of room at the bottom</span>. <a href="https://calteches.library.caltech.edu/1976/1/1960Bottom.pdf">https://calteches.library.caltech.edu/1976/1/1960Bottom.pdf</a>
</div>
<div id="ref-Gabriel_2024_The_ethics_of_advanced_AI_assistants" class="csl-entry" role="doc-biblioentry">
Gabriel, I. et al. (2024). <span class="nocase">The ethics of advanced AI assistants</span>. <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/ethics-of-advanced-ai-assistants/the-ethics-of-advanced-ai-assistants-2024-i.pdf">https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/ethics-of-advanced-ai-assistants/the-ethics-of-advanced-ai-assistants-2024-i.pdf</a>
</div>
<div id="ref-Hanson_2021_If_loud_aliens_explain_human_earliness_quiet" class="csl-entry" role="doc-biblioentry">
Hanson, R., Martin, D., McCarter, C., &amp; Paulson, J. (2021). <span class="nocase">If loud aliens explain human earliness, quiet aliens are also rare.</span> <em>The Astrophysical Journal</em>, <em><span>922</span></em>, 182. <a href="https://iopscience.iop.org/article/10.3847/1538-4357/ac2369">https://iopscience.iop.org/article/10.3847/1538-4357/ac2369</a>
</div>
<div id="ref-Marcus_2018_Deep_learning_A_critical_appraisal" class="csl-entry" role="doc-biblioentry">
Marcus, G. (2018). <span class="nocase">Deep learning: A critical appraisal</span>. <a href="https://arxiv.org/abs/1801.00631">https://arxiv.org/abs/1801.00631</a>
</div>
<div id="ref-Maslej_2023_The_AI_Index_2023_Annual_Report" class="csl-entry" role="doc-biblioentry">
Maslej, N. et al. (2023). <span>The AI Index 2023 Annual Report</span>. <a href="https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI_AI-Index-Report_2023.pdf">https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI_AI-Index-Report_2023.pdf</a>
</div>
<div id="ref-Maslej_2024_The_AI_Index_2024_Annual_Report" class="csl-entry" role="doc-biblioentry">
&#x2014;&#x2014;&#x2014;. (2024). <span>The AI Index 2024 Annual Report</span>. <a href="https://aiindex.stanford.edu/wp-content/uploads/2024/05/HAI_AI-Index-Report-2024.pdf">https://aiindex.stanford.edu/wp-content/uploads/2024/05/HAI_AI-Index-Report-2024.pdf</a>
</div>
<div id="ref-Russell_1995_Artificial_Intelligence_A_modern_approach" class="csl-entry" role="doc-biblioentry">
Russell, S. &amp; Norvig, P. (1995). <em><span class="nocase">Artificial Intelligence: A modern approach</span></em> (3rd ed.). <span>Pearson</span>.
</div>
<div id="ref-Sandberg_2018_Dissolving_the_Fermi_paradox" class="csl-entry" role="doc-biblioentry">
Sandberg, A., Drexler, E., &amp; Ord, T. (2018). <span class="nocase">Dissolving the Fermi paradox</span>. <a href="https://arxiv.org/abs/1806.02404">https://arxiv.org/abs/1806.02404</a>
</div>
<div id="ref-Urban_2015_The_AI_Revolution_The_Road_to_Superintelligence" class="csl-entry" role="doc-biblioentry">
Urban, T. (2015). <span class="nocase">The AI Revolution: The Road to Superintelligence</span>. <a href="https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html">https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html</a>
</div>
<div id="ref-Vincent_2019_OpenAIs_new_multitalented_AI_writes_translates" class="csl-entry" role="doc-biblioentry">
Vincent, J. (2019). <span class="nocase">OpenAI&#x2019;s new multitalented AI writes, translates, and slanders: A step forward in AI text-generation that also spells trouble</span>. <a href="https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2">https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2</a>
</div>
<div id="ref-Vinge_1993_The_coming_technological_singularity" class="csl-entry" role="doc-biblioentry">
Vinge, V. (1993). <span class="nocase">The coming technological singularity</span>. <a href="https://edoras.sdsu.edu/~vinge/misc/singularity.html">https://edoras.sdsu.edu/~vinge/misc/singularity.html</a>
</div>
<div id="ref-Wong_2022_Asymptotic_burnout_and_homeostatic_awakening" class="csl-entry" role="doc-biblioentry">
Wong, M. L. &amp; Bartlett, S. (2022). <span class="nocase">Asymptotic burnout and homeostatic awakening: A possible solution to the Fermi paradox?</span> <em>Journal of the Royal Society Interface</em>, <em><span>19</span></em>, 20220029. <a href="https://royalsocietypublishing.org/doi/full/10.1098/rsif.2022.0029">https://royalsocietypublishing.org/doi/full/10.1098/rsif.2022.0029</a>
</div>
<div id="ref-Zhang_2021_The_AI_Index_2021_Annual_Report" class="csl-entry" role="doc-biblioentry">
Zhang, D. et al. (2021). <span>The AI Index 2021 Annual Report</span>. <span>Human-Centered Artificial Intelligence, Stanford University</span>. <a href="https://arxiv.org/abs/2103.06312">https://arxiv.org/abs/2103.06312</a>
</div>
<div id="ref-Zhang_2022_The_AI_Index_2022_Annual_Report" class="csl-entry" role="doc-biblioentry">
&#x2014;&#x2014;&#x2014;. (2022). <span>The AI Index 2022 Annual Report</span>. <span>Human-Centered Artificial Intelligence, Stanford University</span>. <a href="https://aiindex.stanford.edu/wp-content/uploads/2022/03/2022-AI-Index-Report_Master.pdf">https://aiindex.stanford.edu/wp-content/uploads/2022/03/2022-AI-Index-Report_Master.pdf</a>
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><span class="citation" data-cites="Bostrom_2013_Existential_risk_prevention_as_global_priority">Bostrom (2013)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn2" role="doc-endnote"><p><span class="citation" data-cites="Baum_2019_Long_term_trajectories_of_human_civilization">Baum, S.D. et al. (2019)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn3" role="doc-endnote"><p><span class="citation" data-cites="Bostrom_2019_The_vulnerable_world_hypothesis">Bostrom (2019)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn4" role="doc-endnote"><p><span class="citation" data-cites="Bostrom_2002_Anthropic_Bias_Observation_selection_effects">Bostrom (2002)</span>.<a href="#fnref4" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn5" role="doc-endnote"><p><span class="citation" data-cites="Sandberg_2018_Dissolving_the_Fermi_paradox">Sandberg, Drexler, &amp; Ord (2018)</span>.<a href="#fnref5" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn6" role="doc-endnote"><p><span class="citation" data-cites="Hanson_2021_If_loud_aliens_explain_human_earliness_quiet">Hanson, Martin, McCarter, &amp; Paulson (2021)</span>.<a href="#fnref6" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn7" role="doc-endnote"><p><span class="citation" data-cites="Wong_2022_Asymptotic_burnout_and_homeostatic_awakening">Wong &amp; Bartlett (2022)</span>.<a href="#fnref7" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn8" role="doc-endnote"><p><span class="citation" data-cites="Feynman_1959_Theres_plenty_of_room_at_the_bottom">Feynman (1959)</span>.<a href="#fnref8" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn9" role="doc-endnote"><p><span class="citation" data-cites="Vinge_1993_The_coming_technological_singularity">Vinge (1993)</span>.<a href="#fnref9" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn10" role="doc-endnote"><p><span class="citation" data-cites="Bostrom_2003_Are_you_living_in_a_computer_simulation">Bostrom (2003)</span>.<a href="#fnref10" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn11" role="doc-endnote"><p><span class="citation" data-cites="Bostrom_2011_A_patch_for_the_simulation_argument">Bostrom (2011)</span>.<a href="#fnref11" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn12" role="doc-endnote"><p><span class="citation" data-cites="Russell_1995_Artificial_Intelligence_A_modern_approach">Russell &amp; Norvig (1995)</span>.<a href="#fnref12" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn13" role="doc-endnote"><p><span class="citation" data-cites="Bostrom_2014_Superintelligence_Paths_Dangers_Strategies">Bostrom (2014)</span>.<a href="#fnref13" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn14" role="doc-endnote"><p><span class="citation" data-cites="Armstrong_2014_The_errors_insights_and_lessons_of_famous_AI">Armstrong, Sotala, &amp; OhEigeartaigh (2014)</span>.<a href="#fnref14" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn15" role="doc-endnote"><p><span class="citation" data-cites="Urban_2015_The_AI_Revolution_The_Road_to_Superintelligence">Urban (2015)</span>.<a href="#fnref15" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn16" role="doc-endnote"><p><span class="citation" data-cites="Marcus_2018_Deep_learning_A_critical_appraisal">Marcus (2018)</span>.<a href="#fnref16" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn17" role="doc-endnote"><p><span class="citation" data-cites="Zhang_2021_The_AI_Index_2021_Annual_Report">Zhang, D. et al. (2021)</span>.<a href="#fnref17" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn18" role="doc-endnote"><p><span class="citation" data-cites="Zhang_2022_The_AI_Index_2022_Annual_Report">Zhang, D. et al. (2022)</span>.<a href="#fnref18" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn19" role="doc-endnote"><p><span class="citation" data-cites="Bubeck_2023_Sparks_of_Artificial_General_Intelligence_Early">Bubeck, S. et al. (2023)</span>.<a href="#fnref19" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn20" role="doc-endnote"><p><span class="citation" data-cites="Maslej_2023_The_AI_Index_2023_Annual_Report">Maslej, N. et al. (2023)</span>.<a href="#fnref20" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn21" role="doc-endnote"><p><span class="citation" data-cites="Maslej_2024_The_AI_Index_2024_Annual_Report">Maslej, N. et al. (2024)</span>.<a href="#fnref21" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn22" role="doc-endnote"><p><span class="citation" data-cites="Aschenbrenner_2024_Situational_Awareness_The_decade_ahead">Aschenbrenner (2024)</span>.<a href="#fnref22" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn23" role="doc-endnote"><p><span class="citation" data-cites="Vincent_2019_OpenAIs_new_multitalented_AI_writes_translates">Vincent (2019)</span>.<a href="#fnref23" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn24" role="doc-endnote"><p><span class="citation" data-cites="Gabriel_2024_The_ethics_of_advanced_AI_assistants">Gabriel, I. et al. (2024)</span>.<a href="#fnref24" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn25" role="doc-endnote"><p><span class="citation" data-cites="Bostrom_2005_The_fable_of_the_dragon_tyrant">Bostrom (2005)</span>.<a href="#fnref25" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
</ol>
</section>

</div> <!-- end pagecontainer -->
</div> <!-- end mainbody -->

<div class="nav">
<ul>
    <li> <a href="./">&#8634;&nbsp;Contents</a> </li>
    <li> <a href="#site_header">&#8613;&nbsp;Top</a> </li>
    <li> <a href="./human-condition.html">&#8612;&nbsp;Previous</a> </li>
</ul>
</div>

<!--
<div id="afterbody">
</div>
-->

<div id="site_footer">
  <div class="signature">
    <p><i>Ryan Reece</i></p>
    <p><a href="https://twitter.com/RyanDavidReece">@RyanDavidReece</a><br/><img class="email" src="img/my-email-alt-blue.png" alt="my email address"/></p>
    <p>Sat Jun 08, 2024</p>
  </div>
  <div class="license">
    <p>&#xA9; 2014-2024 <a href="http://rreece.github.io/">Ryan Reece</a>. All rights reserved.</p>
    <p>Made with <a href="https://github.com/rreece/markdown-memo">markdown-memo</a>.</p>
  </div>
  <div style="clear:both;"></div>
</div>

<!-- disqus stuff -->
<div id="disqus_stuff">
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'ryans-outline-of-philosophy';
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript><p>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></p></noscript>

<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'ryans-outline-of-philosophy';
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</div> <!-- end disqus_stuff -->

</body>
</html>
